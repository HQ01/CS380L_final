--- ../coreutils-8.32/src/copy.c	2020-01-01 08:13:12.000000000 -0600
+++ ./copy_uring.c	2020-12-06 00:23:07.152546645 -0600
@@ -15,13 +15,15 @@
    along with this program.  If not, see <https://www.gnu.org/licenses/>.  */
 
 /* Extracted from cp.c and librarified by Jim Meyering.  */
-
+#define _GNU_SOURCE
 #include <config.h>
 #include <stdio.h>
 #include <assert.h>
 #include <sys/ioctl.h>
 #include <sys/types.h>
 #include <selinux/selinux.h>
+#include <liburing.h>
+#include <math.h>
 
 #if HAVE_HURD_H
 # include <hurd.h>
@@ -35,7 +37,7 @@
 #include "backupfile.h"
 #include "buffer-lcm.h"
 #include "canonicalize.h"
-#include "copy.h"
+#include "copy_uring.h"
 #include "cp-hash.h"
 #include "extent-scan.h"
 #include "die.h"
@@ -128,10 +130,91 @@
   ino_t ino;
   dev_t dev;
 };
-
 /* Initial size of the cp.dest_info hash table.  */
 #define DEST_INFO_INITIAL_CAPACITY 61
 
+/* AIO configurations */
+#define AIO_BLKSIZE (128 * 1024)    // I/O block size
+#define QD 64                       // I/O queue depth
+
+struct aio_data {
+    int src_fd;
+    int dst_fd;
+    off_t offset;
+    int buf_index;
+    bool is_read;
+    char const *src_name;
+    char const *dst_name;
+};
+
+struct io_uring aio_ring;
+int inflight = 0;
+
+/* AIO buffer queue */
+int aio_buf_queue[QD];
+struct iovec aio_buf[QD];
+int aio_buf_qhead, aio_buf_qtail;
+
+int aio_buf_queue_init() {
+    aio_buf_qhead = 0;
+    aio_buf_qtail = QD - 1;
+    for (int i = 0; i < QD; i++) 
+    {
+        // allocate AIO buffer
+        aio_buf[i].iov_base = NULL;
+        // aio_buf[i].iov_base = malloc(AIO_BLKSIZE);
+        posix_memalign((void **)&aio_buf[i].iov_base, getpagesize(), AIO_BLKSIZE);
+        if (aio_buf[i].iov_base == NULL)
+        {
+            fprintf(stderr, "error allocating AIO buffer\n");
+            return -1;
+        }
+        aio_buf[i].iov_len = AIO_BLKSIZE;
+        memset(aio_buf[i].iov_base, 0, AIO_BLKSIZE);
+
+        // initialize buffer queue
+        aio_buf_queue[i] = i;
+    }
+    return 0;
+}
+
+void aio_buf_queue_destroy()
+{
+    for (int i = 0; i < QD; i++)
+        free(aio_buf[i].iov_base);
+}
+
+int aio_buf_enqueue(int buf_index) 
+{
+    int tmp = aio_buf_qtail;
+    aio_buf_qtail = (aio_buf_qtail + 1) % QD;
+    if (aio_buf_queue[aio_buf_qtail] >= 0) 
+    {
+        aio_buf_qtail = tmp;
+        return -1;
+    }
+    aio_buf_queue[aio_buf_qtail] = buf_index;
+    return 0;
+}
+
+int aio_buf_dequeue() 
+{
+    if (aio_buf_queue[aio_buf_qhead] < 0) return -1;
+    int buf_index = aio_buf_queue[aio_buf_qhead];
+    aio_buf_queue[aio_buf_qhead] = -1;
+    aio_buf_qhead = (aio_buf_qhead + 1) % QD;
+    return buf_index;
+}
+
+/* AIO utils */
+void aio_exit(bool fatal_error);
+void aio_free_data(struct aio_data *data);
+void aio_prep_rw(struct aio_data *data);
+void aio_submit(int ready, char const *file_name, bool is_read);
+bool aio_proc_cqe(struct io_uring_cqe *cqe, off_t *total_n_read, bool *write_comp, bool io_error);
+bool aio_wait_all_comp(off_t *total_n_read, bool io_error);
+
+
 static bool copy_internal (char const *src_name, char const *dst_name,
                            bool new_dst, struct stat const *parent,
                            struct dir_list *ancestors,
@@ -244,6 +327,155 @@
   return true;
 }
 
+/* AIO utils: exit AIO
+   If fatal AIO error occurs, such as errors in getting/releasing buffer
+   and getting completed requests, the program will exit.
+   Otherwise destroy AIO buffer queue and exit AIO normally.  */
+void aio_exit(bool fatal_error)
+{
+  io_uring_queue_exit(&aio_ring);
+  aio_buf_queue_destroy();
+
+  if (fatal_error) exit(1);
+}
+
+/* AIO utils: free AIO data and release buffer back to queue */
+void aio_free_data(struct aio_data *data)
+{
+  if (aio_buf_enqueue(data->buf_index) < 0) 
+  {
+    fprintf(stderr, "error releasing buffer back to AIO buffer queue\n");
+    aio_exit(true);
+  } 
+  free(data);
+}
+
+/* AIO utils: prepare for read/write */
+void aio_prep_rw(struct aio_data *data) 
+{
+  struct io_uring_sqe *sqe = io_uring_get_sqe(&aio_ring);
+  if (data->is_read)
+      io_uring_prep_read_fixed(sqe, data->src_fd, aio_buf[data->buf_index].iov_base, 
+                               aio_buf[data->buf_index].iov_len, data->offset, data->buf_index);
+  else 
+      io_uring_prep_write_fixed(sqe, data->dst_fd, aio_buf[data->buf_index].iov_base, 
+                                aio_buf[data->buf_index].iov_len, data->offset, data->buf_index);
+  io_uring_sqe_set_data(sqe, data);
+
+  // if (data->is_read)
+  //   fprintf(stderr, "reading %s at offset %ld with length %ld using buffer with index %d\n", 
+  //           data->src_name, data->offset, aio_buf[data->buf_index].iov_len, data->buf_index);
+  // else
+  //   fprintf(stderr, "writing %s at offset %ld with length %ld using buffer with index %d\n", 
+  //           data->dst_name, data->offset, aio_buf[data->buf_index].iov_len, data->buf_index);
+}
+
+/* AIO utils: submit prepared I/O requests */
+void aio_submit(int ready, char const *file_name, bool is_read)
+{
+  int ret;
+  while (ready) 
+  {
+    ret = io_uring_submit(&aio_ring);
+    // fprintf(stderr, "ready: %d; ret: %d\n", ready, ret);
+
+    if (ret < 0) 
+    {
+      if (is_read)
+        fprintf(stderr, "error submitting I/O requests when reading %s: %s\n", file_name, strerror(-ret));
+      else
+        fprintf(stderr, "error submitting I/O requests when writing %s: %s\n", file_name, strerror(-ret));  
+      aio_exit(true);
+    }
+    else if (ret == 0)
+    {
+      if (is_read)
+        fprintf(stderr, "error submitting I/O requests when reading %s: no submission\n", file_name);
+      else
+        fprintf(stderr, "error submitting I/O requests when writing %s: no submission\n", file_name);  
+      aio_exit(true);
+    }
+
+    ready -= ret;
+    inflight += ret;
+  }
+}
+
+/* AIO utils: process the completed I/O requests */
+bool aio_proc_cqe(struct io_uring_cqe *cqe, off_t *total_n_read, bool *write_comp, bool io_error)
+{
+  int ret;
+  struct aio_data *data = io_uring_cqe_get_data(cqe);
+  inflight--;
+
+  // do not process the completed request if an I/O error has occured
+  if (io_error)
+  {
+    io_uring_cqe_seen(&aio_ring, cqe);
+    aio_free_data(data);
+    return false;
+  }
+
+  // resubmit the request if I/O request is canceled or incomplete
+  if (cqe->res == -EAGAIN || cqe->res == -ECANCELED || (cqe->res >= 0 && cqe->res != aio_buf[data->buf_index].iov_len))
+  {
+    aio_prep_rw(data);
+    io_uring_cqe_seen(&aio_ring, cqe);
+    aio_submit(1, data->is_read ? data->src_name : data->dst_name, data->is_read);
+  }
+  // I/O error
+  else if (cqe->res < 0) 
+  {
+    ret = cqe->res;
+    io_uring_cqe_seen(&aio_ring, cqe);
+    
+    if (data->is_read)
+      fprintf(stderr, "error reading %s: %s\n", data->src_name, strerror(-ret));
+    else
+      fprintf(stderr, "error writing %s: %s\n", data->dst_name, strerror(-ret)); 
+    aio_free_data(data);
+    return false;
+  } 
+  // a successful read launches the corresponding write
+  else if (data->is_read)
+  {
+    *total_n_read += aio_buf[data->buf_index].iov_len;
+    data->is_read = false;
+    aio_prep_rw(data);
+    io_uring_cqe_seen(&aio_ring, cqe);
+    aio_submit(1, data->dst_name, false);
+  }
+  // a successful write results in an available entry in AIO queue and an availble AIO buffer
+  else 
+  {
+    io_uring_cqe_seen(&aio_ring, cqe);
+    // if cnt is reduced to 0, close file
+    aio_free_data(data);
+    if (write_comp) *write_comp = true;
+  }
+
+  return true;
+}
+
+/* AIO utils: wait for all inflight requests to complete
+   It returns false if any completed request gives an error, but does not
+   return immediately when error of a request occurs. */
+bool aio_wait_all_comp(off_t *total_n_read, bool io_error)
+{
+  struct io_uring_cqe *cqe;
+  while (inflight > 0)
+  {
+      // fprintf(stderr, "inflight: %d\n", inflight);
+      int ret = io_uring_wait_cqe(&aio_ring, &cqe);
+      if (ret < 0) 
+      {
+          fprintf(stderr, "error getting completed I/O requests: %s\n", strerror(-ret));
+          aio_exit(true);
+      }
+      io_error |= !aio_proc_cqe(cqe, total_n_read, NULL, io_error);
+  }
+  return !io_error;
+}
 
 /* Copy the regular file open on SRC_FD/SRC_NAME to DST_FD/DST_NAME,
    honoring the MAKE_HOLES setting and using the BUF_SIZE-byte buffer
@@ -257,109 +489,95 @@
    DEST_FD introduced a hole.  Set *TOTAL_N_READ to the number of
    bytes read.  */
 static bool
-sparse_copy (int src_fd, int dest_fd, char *buf, size_t buf_size,
+sparse_copy (int src_fd, int dest_fd,
              size_t hole_size, bool punch_holes,
              char const *src_name, char const *dst_name,
              uintmax_t max_n_read, off_t *total_n_read,
+             int start_offset, //AIO
              bool *last_write_made_hole)
 {
   *last_write_made_hole = false;
   *total_n_read = 0;
   bool make_hole = false;
-  off_t psize = 0;
-
-  while (max_n_read)
-    {
-      ssize_t n_read = read (src_fd, buf, MIN (max_n_read, buf_size));
-      if (n_read < 0)
-        {
-          if (errno == EINTR)
-            continue;
-          error (0, errno, _("error reading %s"), quoteaf (src_name));
-          return false;
-        }
-      if (n_read == 0)
-        break;
-      max_n_read -= n_read;
-      *total_n_read += n_read;
-
-      /* Loop over the input buffer in chunks of hole_size.  */
-      size_t csize = hole_size ? hole_size : buf_size;
-      char *cbuf = buf;
-      char *pbuf = buf;
-
-      while (n_read)
-        {
-          bool prev_hole = make_hole;
-          csize = MIN (csize, n_read);
-
-          if (hole_size && csize)
-            make_hole = is_nul (cbuf, csize);
-
-          bool transition = (make_hole != prev_hole) && psize;
-          bool last_chunk = (n_read == csize && ! make_hole) || ! csize;
-
-          if (transition || last_chunk)
-            {
-              if (! transition)
-                psize += csize;
-
-              if (! prev_hole)
-                {
-                  if (full_write (dest_fd, pbuf, psize) != psize)
-                    {
-                      error (0, errno, _("error writing %s"),
-                             quoteaf (dst_name));
-                      return false;
-                    }
-                }
-              else
-                {
-                  if (! create_hole (dest_fd, dst_name, punch_holes, psize))
-                    return false;
-                }
-
-              pbuf = cbuf;
-              psize = csize;
-
-              if (last_chunk)
-                {
-                  if (! csize)
-                    n_read = 0; /* Finished processing buffer.  */
-
-                  if (transition)
-                    csize = 0;  /* Loop again to deal with last chunk.  */
-                  else
-                    psize = 0;  /* Reset for next read loop.  */
-                }
-            }
-          else  /* Coalesce writes/seeks.  */
-            {
-              if (INT_ADD_WRAPV (psize, csize, &psize))
-                {
-                  error (0, 0, _("overflow reading %s"), quoteaf (src_name));
-                  return false;
-                }
-            }
+  off_t offset = start_offset;
+  int ret;
 
-          n_read -= csize;
-          cbuf += csize;
-        }
+  while (max_n_read) 
+  {
+    int ready = 0;
 
-      *last_write_made_hole = make_hole;
+    // prepare as many reads as possible
+    while (max_n_read && inflight + ready < QD) 
+    {
+      off_t io_size = (max_n_read < AIO_BLKSIZE) ? max_n_read : AIO_BLKSIZE;
 
-      /* It's tempting to break early here upon a short read from
-         a regular file.  That would save the final read syscall
-         for each file.  Unfortunately that doesn't work for
-         certain files in /proc or /sys with linux kernels.  */
-    }
+      struct aio_data *data = NULL;
+      data = (struct aio_data *)malloc(sizeof(struct aio_data));
+      if (data == NULL) 
+      {
+        fprintf(stderr, "error allocating aio_data when reading %s\n", src_name);
+        if (ready) aio_submit(ready, src_name, true);
+        aio_wait_all_comp(total_n_read, true);
+        return false;
+      }
 
-  /* Ensure a trailing hole is created, so that subsequent
-     calls of sparse_copy() start at the correct offset.  */
-  if (make_hole && ! create_hole (dest_fd, dst_name, punch_holes, psize))
-    return false;
-  else
-    return true;
+      data->src_fd = src_fd;
+      data->dst_fd = dest_fd;
+      data->offset = offset;
+      data->buf_index = aio_buf_dequeue();
+      if (data->buf_index < 0)
+      {
+        fprintf(stderr, "error getting buffer from aio_buf_queue when reading %s\n", src_name);
+        aio_exit(true);
+      }
+      aio_buf[data->buf_index].iov_len = io_size;
+      data->is_read = true;
+      data->src_name = src_name;
+      data->dst_name = dst_name;
+
+      aio_prep_rw(data);
+
+      offset += io_size;
+      max_n_read -= io_size;
+      ready++;
+    }
+
+    // submit prepared I/O requests
+    if (ready) aio_submit(ready, src_name, true);
+
+    // process events from completed requests
+    if (inflight >= QD) 
+    {
+      struct io_uring_cqe *cqe;
+      struct aio_data *data;
+      bool write_comp = false;
+      while (1)
+      {
+        if (write_comp) // use unblocked wait to get more available events
+        {
+          ret = io_uring_peek_cqe(&aio_ring, &cqe);
+          if (ret == -EAGAIN) break;  // break the loop if no available events
+        }
+        else // use blocked wait to get at least one event
+          ret = io_uring_wait_cqe(&aio_ring, &cqe);
+        
+        if (ret < 0) 
+        {
+          fprintf(stderr, "error getting completed I/O requests: %s\n", strerror(-ret));
+          aio_exit(true);
+        }
+
+        if (!aio_proc_cqe(cqe, total_n_read, &write_comp, false)) return aio_wait_all_comp(total_n_read, true);
+      }
+    }
+  }
+  // fprintf(stderr, "All reads are submitted\n");
+
+  // bool ok = aio_wait_all_comp(total_n_read, false);
+  // fprintf(stderr, "%s: all requests are done\n", ok ? "Success" : "Failure");
+  // fprintf(stderr, "queue head: %d; queue tail: %d\n", aio_buf_qhead, aio_buf_qtail);
+  // return ok;
+  return aio_wait_all_comp(total_n_read, false);
 }
 
 /* Perform the O(1) btrfs clone operation, if possible.
@@ -418,7 +636,7 @@
    Upon any other failure, set *NORMAL_COPY_REQUIRED to false and
    return false.  */
 static bool
-extent_copy (int src_fd, int dest_fd, char *buf, size_t buf_size,
+extent_copy (int src_fd, int dest_fd,
              size_t hole_size, off_t src_total_size,
              enum Sparse_type sparse_mode,
              char const *src_name, char const *dst_name,
@@ -553,9 +771,10 @@
               last_ext_len = ext_len;
               bool read_hole;
 
-              if ( ! sparse_copy (src_fd, dest_fd, buf, buf_size,
+              if ( ! sparse_copy (src_fd, dest_fd,
                                   sparse_mode == SPARSE_ALWAYS ? hole_size: 0,
                                   true, src_name, dst_name, ext_len, &n_read,
+                                  dest_pos,
                                   &read_hole))
                 goto fail;
 
@@ -1052,8 +1271,8 @@
           mode_t dst_mode, mode_t omitted_permissions, bool *new_dst,
           struct stat const *src_sb)
 {
-  char *buf;
-  char *buf_alloc = NULL;
+  // char *buf;
+  // char *buf_alloc = NULL;
   char *name_alloc = NULL;
   int dest_desc;
   int dest_errno;
@@ -1157,7 +1376,7 @@
       dest_desc = open (dst_name, open_flags | O_EXCL,
                         dst_mode & ~omitted_permissions);
       dest_errno = errno;
-
+      
       /* When trying to copy through a dangling destination symlink,
          the above open fails with EEXIST.  If that happens, and
          lstat'ing the DST_NAME shows that it is a symlink, then we
@@ -1226,6 +1445,13 @@
       goto close_src_desc;
     }
 
+  // if (ftruncate(dest_desc, src_open_sb.st_size) != 0)
+  //   {
+  //     error (0, errno, _("cannot ftruncate %s"), quoteaf (dst_name));
+  //     return_val = false;
+  //     goto close_src_and_dst_desc;
+  //   }
+
   if (fstat (dest_desc, &sb) != 0)
     {
       error (0, errno, _("cannot fstat %s"), quoteaf (dst_name));
@@ -1253,8 +1479,8 @@
   if (data_copy_required)
     {
       /* Choose a suitable buffer size; it may be adjusted later.  */
-      size_t buf_alignment = getpagesize ();
-      size_t buf_size = io_blksize (sb);
+      // size_t buf_alignment = getpagesize ();
+      // size_t buf_size = io_blksize (sb);
       size_t hole_size = ST_BLKSIZE (sb);
 
       fdadvise (source_desc, 0, 0, FADVISE_SEQUENTIAL);
@@ -1278,32 +1504,32 @@
             make_holes = true;
         }
 
-      /* If not making a sparse file, try to use a more-efficient
-         buffer size.  */
-      if (! make_holes)
-        {
-          /* Compute the least common multiple of the input and output
-             buffer sizes, adjusting for outlandish values.  */
-          size_t blcm_max = MIN (SIZE_MAX, SSIZE_MAX) - buf_alignment;
-          size_t blcm = buffer_lcm (io_blksize (src_open_sb), buf_size,
-                                    blcm_max);
-
-          /* Do not bother with a buffer larger than the input file, plus one
-             byte to make sure the file has not grown while reading it.  */
-          if (S_ISREG (src_open_sb.st_mode) && src_open_sb.st_size < buf_size)
-            buf_size = src_open_sb.st_size + 1;
-
-          /* However, stick with a block size that is a positive multiple of
-             blcm, overriding the above adjustments.  Watch out for
-             overflow.  */
-          buf_size += blcm - 1;
-          buf_size -= buf_size % blcm;
-          if (buf_size == 0 || blcm_max < buf_size)
-            buf_size = blcm;
-        }
+      // /* If not making a sparse file, try to use a more-efficient
+      //    buffer size.  */
+      // if (! make_holes)
+      //   {
+      //     /* Compute the least common multiple of the input and output
+      //        buffer sizes, adjusting for outlandish values.  */
+      //     size_t blcm_max = MIN (SIZE_MAX, SSIZE_MAX) - buf_alignment;
+      //     size_t blcm = buffer_lcm (io_blksize (src_open_sb), buf_size,
+      //                               blcm_max);
+
+      //     /* Do not bother with a buffer larger than the input file, plus one
+      //        byte to make sure the file has not grown while reading it.  */
+      //     if (S_ISREG (src_open_sb.st_mode) && src_open_sb.st_size < buf_size)
+      //       buf_size = src_open_sb.st_size + 1;
+
+      //     /* However, stick with a block size that is a positive multiple of
+      //        blcm, overriding the above adjustments.  Watch out for
+      //        overflow.  */
+      //     buf_size += blcm - 1;
+      //     buf_size -= buf_size % blcm;
+      //     if (buf_size == 0 || blcm_max < buf_size)
+      //       buf_size = blcm;
+      //   }
 
-      buf_alloc = xmalloc (buf_size + buf_alignment);
-      buf = ptr_align (buf_alloc, buf_alignment);
+      // buf_alloc = xmalloc (buf_size + buf_alignment);
+      // buf = ptr_align (buf_alloc, buf_alignment);
 
       if (sparse_src)
         {
@@ -1313,7 +1539,7 @@
              standard copy only if the initial extent scan fails.  If the
              '--sparse=never' option is specified, write all data but use
              any extents to read more efficiently.  */
-          if (extent_copy (source_desc, dest_desc, buf, buf_size, hole_size,
+          if (extent_copy (source_desc, dest_desc, hole_size,
                            src_open_sb.st_size,
                            make_holes ? x->sparse_mode : SPARSE_NEVER,
                            src_name, dst_name, &normal_copy_required))
@@ -1328,10 +1554,11 @@
 
       off_t n_read;
       bool wrote_hole_at_eof;
-      if (! sparse_copy (source_desc, dest_desc, buf, buf_size,
+      if (! sparse_copy (source_desc, dest_desc,
                          make_holes ? hole_size : 0,
                          x->sparse_mode == SPARSE_ALWAYS, src_name, dst_name,
-                         UINTMAX_MAX, &n_read,
+                         src_open_sb.st_size, &n_read,
+                         0,
                          &wrote_hole_at_eof))
         {
           return_val = false;
@@ -1444,7 +1671,7 @@
       return_val = false;
     }
 
-  free (buf_alloc);
+  // free (buf_alloc);
   free (name_alloc);
   return return_val;
 }
@@ -3010,6 +3237,27 @@
 {
   assert (valid_options (options));
 
+  // initialize AIO buffer queue
+  int ret = io_uring_queue_init(QD, &aio_ring, 0);
+  if (ret < 0) 
+  {
+    fprintf(stderr, "error initializing io_uring: %s\n", strerror(-ret));
+    return false;
+  }
+
+  // initialize AIO buffer queue
+  ret = aio_buf_queue_init();
+  if (ret < 0) return false;
+
+  // register AIO buffer
+  ret = io_uring_register_buffers(&aio_ring, aio_buf, QD);
+  if (ret < 0)
+  {
+    fprintf(stderr, "Fail to register buffer: %s\n", strerror(-ret));
+    aio_exit(false);
+    return false;
+  }
+
   /* Record the file names: they're used in case of error, when copying
      a directory into itself.  I don't like to make these tools do *any*
      extra work in the common case when that work is solely to handle
@@ -3021,10 +3269,13 @@
   top_level_dst_name = dst_name;
 
   bool first_dir_created_per_command_line_arg = false;
-  return copy_internal (src_name, dst_name, nonexistent_dst, NULL, NULL,
-                        options, true,
-                        &first_dir_created_per_command_line_arg,
-                        copy_into_self, rename_succeeded);
+  bool ok = copy_internal (src_name, dst_name, nonexistent_dst, NULL, NULL,
+                          options, true,
+                          &first_dir_created_per_command_line_arg,
+                          copy_into_self, rename_succeeded);
+
+  aio_exit(false);
+  return ok;
 }
 
 /* Set *X to the default options for a value of type struct cp_options.  */
